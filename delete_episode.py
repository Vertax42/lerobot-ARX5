#!/usr/bin/env python3
"""
åˆ é™¤æŒ‡å®šçš„ episode å¹¶æ›´æ–°æ‰€æœ‰ metadataã€‚

ç”¨æ³•:
    python delete_episode.py --dataset-path /path/to/dataset --episode-index 3
"""

import argparse
import json
import shutil
from pathlib import Path


def delete_episode(dataset_path: Path, episode_index: int):
    """åˆ é™¤æŒ‡å®šçš„ episode å¹¶æ›´æ–° metadata"""

    print(f"ğŸ—‘ï¸  æ­£åœ¨åˆ é™¤ Episode {episode_index}...")

    # 1. åˆ é™¤ parquet æ–‡ä»¶
    episode_chunk = episode_index // 1000  # é»˜è®¤ chunks_size = 1000
    parquet_file = (
        dataset_path
        / f"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet"
    )
    if parquet_file.exists():
        print(f"   âœ“ åˆ é™¤ parquet: {parquet_file}")
        parquet_file.unlink()
    else:
        print(f"   âš ï¸  parquet æ–‡ä»¶ä¸å­˜åœ¨: {parquet_file}")

    # 2. åˆ é™¤è§†é¢‘æ–‡ä»¶
    videos_dir = dataset_path / f"videos/chunk-{episode_chunk:03d}"
    if videos_dir.exists():
        for camera_dir in videos_dir.iterdir():
            if camera_dir.is_dir():
                video_file = camera_dir / f"episode_{episode_index:06d}.mp4"
                if video_file.exists():
                    print(f"   âœ“ åˆ é™¤è§†é¢‘: {video_file}")
                    video_file.unlink()

    # 3. åˆ é™¤å›¾åƒæ–‡ä»¶å¤¹ï¼ˆå¦‚æœæœ‰ï¼‰
    images_dir = dataset_path / f"images/chunk-{episode_chunk:03d}"
    if images_dir.exists():
        for camera_dir in images_dir.iterdir():
            if camera_dir.is_dir():
                image_folder = camera_dir / f"episode_{episode_index:06d}"
                if image_folder.exists():
                    print(f"   âœ“ åˆ é™¤å›¾åƒæ–‡ä»¶å¤¹: {image_folder}")
                    shutil.rmtree(image_folder)

    # 4. è¯»å– episodes.jsonl
    episodes_file = dataset_path / "meta/episodes.jsonl"
    episodes = []
    deleted_episode_length = 0

    with open(episodes_file, "r") as f:
        for line in f:
            ep = json.loads(line)
            if ep["episode_index"] != episode_index:
                episodes.append(ep)
            else:
                deleted_episode_length = ep["length"]
                print(
                    f"   ğŸ“Š Episode {episode_index} é•¿åº¦: {deleted_episode_length} å¸§"
                )

    # å†™å› episodes.jsonlï¼ˆä¸åŒ…å«è¢«åˆ é™¤çš„ episodeï¼‰
    with open(episodes_file, "w") as f:
        for ep in episodes:
            f.write(json.dumps(ep) + "\n")
    print(f"   âœ“ æ›´æ–° episodes.jsonl")

    # 5. è¯»å– episodes_stats.jsonl
    stats_file = dataset_path / "meta/episodes_stats.jsonl"
    stats_lines = []

    with open(stats_file, "r") as f:
        for line in f:
            stat = json.loads(line)
            if stat["episode_index"] != episode_index:
                stats_lines.append(line)

    # å†™å› episodes_stats.jsonl
    with open(stats_file, "w") as f:
        for line in stats_lines:
            f.write(line)
    print(f"   âœ“ æ›´æ–° episodes_stats.jsonl")

    # 6. æ›´æ–° info.json
    info_file = dataset_path / "meta/info.json"
    with open(info_file, "r") as f:
        info = json.load(f)

    old_total_episodes = info["total_episodes"]
    old_total_frames = info["total_frames"]
    old_total_videos = info["total_videos"]

    # æ›´æ–°è®¡æ•°
    info["total_episodes"] -= 1
    info["total_frames"] -= deleted_episode_length
    info["total_videos"] -= 3  # å‡è®¾æœ‰ 3 ä¸ªç›¸æœº

    # æ›´æ–° splits
    info["splits"]["train"] = f"0:{info['total_episodes']}"

    # å†™å› info.json
    with open(info_file, "w") as f:
        json.dump(info, f, indent=4)

    print(f"   âœ“ æ›´æ–° info.json:")
    print(f"      - total_episodes: {old_total_episodes} â†’ {info['total_episodes']}")
    print(f"      - total_frames: {old_total_frames} â†’ {info['total_frames']}")
    print(f"      - total_videos: {old_total_videos} â†’ {info['total_videos']}")
    print(f"      - splits: {info['splits']}")

    print(f"\nâœ… Episode {episode_index} å·²æˆåŠŸåˆ é™¤ï¼")
    print(
        f"\nâš ï¸  æ³¨æ„: è¢«åˆ é™¤çš„ episode ç´¢å¼•å· {episode_index} ä¸ä¼šè¢«åç»­ episode é‡ç”¨ã€‚"
    )
    print(f"   ä¸‹æ¬¡å½•åˆ¶æ–° episode æ—¶ï¼Œç´¢å¼•ä¼šä» {old_total_episodes} å¼€å§‹ã€‚")


def main():
    parser = argparse.ArgumentParser(description="åˆ é™¤ LeRobot æ•°æ®é›†ä¸­çš„æŒ‡å®š episode")
    parser.add_argument(
        "--dataset-path",
        type=str,
        default="/home/vertax/.cache/huggingface/lerobot/Vertax/xense_bi_arx5_tie_shoelaces",
        required=True,
        help="æ•°æ®é›†è·¯å¾„ï¼ˆä¾‹å¦‚: /home/vertax/.cache/huggingface/lerobot/Vertax/xense_bi_arx5_tie_shoelacesï¼‰",
    )
    parser.add_argument(
        "--episode-index", type=int, required=True, help="è¦åˆ é™¤çš„ episode ç´¢å¼•"
    )

    args = parser.parse_args()
    dataset_path = Path(args.dataset_path)

    if not dataset_path.exists():
        print(f"âŒ é”™è¯¯: æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {dataset_path}")
        return

    # ç¡®è®¤æ“ä½œ
    print(f"\nâš ï¸  è­¦å‘Š: å³å°†åˆ é™¤ä»¥ä¸‹æ•°æ®é›†çš„ Episode {args.episode_index}:")
    print(f"   æ•°æ®é›†è·¯å¾„: {dataset_path}")
    print(f"   Episode ç´¢å¼•: {args.episode_index}")

    response = input("\nç¡®è®¤åˆ é™¤å—ï¼Ÿ (yes/no): ")
    if response.lower() != "yes":
        print("âŒ æ“ä½œå·²å–æ¶ˆ")
        return

    delete_episode(dataset_path, args.episode_index)


if __name__ == "__main__":
    main()
